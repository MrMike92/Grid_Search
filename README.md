# Grid_Search

> [!WARNING]
> En esta rama solo se encuentra las versiones finales de los c贸digos, para ver m谩s detalles, vaya a la rama test_config_programs.

Grid Search es un m茅todo de optimizaci贸n que se utiliza en el aprendizaje autom谩tico para ajustar hiperpar谩metros, esta consiste en probar todas las combinaciones posibles de los valores de hiperpar谩metros para encontrar el modelo que mejor se adapte a los datos.

Los hiperpar谩metros controlan la estructura, las funciones y el rendimiento de los modelos. Ajustar los hiperpar谩metros permite modificar el rendimiento del modelo para obtener resultados 贸ptimos.

El grid search funciona de la siguiente manera:
- Se entrena un modelo para cada combinaci贸n de hiperpar谩metros.
- Se selecciona el modelo que mejor se desempe帽a.

## Funcionamiento

1. Se cargan el conjunto de datos desde un archivo CSV y se eliminan cualquier fila que contenga valores faltantes (valores nulos/NaN) para evitar errores durante el entrenamiento, a continuaci贸n, se separan las caracter铆sticas (variables predictoras) de la variable objetivo, que indica la potabilidad del agua, luego, el conjunto de datos se divide en dos partes: datos de entrenamiento y datos de prueba. Los primeros se utilizan para entrenar los modelos, mientras que los segundos permiten evaluar el rendimiento de estos (relaci贸n 80% de entrenamiento y 20% de pruebas).

2. Con el usa del procesamiento paralelo, se reparte el trabajo de probar distintas combinaciones de hiperpar谩metros, que, dependiendo de la cantidad de hilos seleccionados, se divide la carga de trabajo entre los procesos disponibles de forma ***equitativa***. Pero los procesos internos del modelo se hacen de forma secuencial.

3. Se realizan las pruebas de forma simult谩neo en varios hilos en lugar de forma secuencial con diferentes combinaciones de par谩metros, que se eval煤an en t茅rminos de precisi贸n en la clasificaci贸n y el tiempo que toma entrenar para predecir con cada configuraci贸n.

4. Cada modelo es evaluado con base en la precisi贸n de la clasificaci贸n, que mide el porcentaje de predicciones correctas en el conjunto de prueba y el tiempo de ejecuci贸n tambi茅n es un factor clave que se toma en cuenta, ya que ayuda a identificar qu茅 modelos y configuraciones son m谩s eficientes en t茅rminos computacionales.

5. Tras la ejecuci贸n de las pruebas, se analizan los resultados para encontrar la mejor y la peor combinaci贸n de par谩metros en la precisi贸n de la clasificaci贸n para cada modelo, esto para dar una visi贸n global del rendimiento del modelo bajo distintas configuraciones.

6. Al final se imprimen los resultados detallados, incluyendo la mejor y peor precisi贸n obtenida, as铆 como el tiempo de ejecuci贸n para cada n煤mero de hilos utilizados de cada uno de los modelos utilizados: ***una red neuronal artificial (ANN), Random Forest, XGBoost y Naive Bayes***.

Esto proporciona una visi贸n clara del balance entre precisi贸n, sensibilidad y costo computacional, esto es fundamental para la toma de decisiones sobre qu茅 modelo utilizar en la pr谩ctica.

## Resultados.

El rendimiento general de Random Forest fue bastante estable, con precisiones y recalls promedios rondando los 0.932, sin embargo, los mejores resultados variaron ligeramente seg煤n el n煤mero de hilos, con un desempe帽o 贸ptimo en 3 y 7 hilos (precisi贸n y recall de 0.941176). Este rendimiento 贸ptimo se logr贸 con configuraciones que implicaban un mayor n煤mero de estimadores (n\_estimators=100), mayor profundidad (max_depth=30) y un tama帽o m铆nimo de divisi贸n de muestras de 5, combinado con un m铆nimo de 2 hojas por divisi贸n.

Estas configuraciones m谩s complejas en cuanto a profundidad y n煤mero de estimadores parecen haber proporcionado mejor rendimiento, aunque el tiempo de ejecuci贸n aument贸 proporcionalmente a medida que el n煤mero de hilos aumentaba, en general, mientras que una mayor complejidad en los hiperpar谩metros mejor贸 ligeramente el rendimiento en precisi贸n y recall, tambi茅n increment贸 considerablemente el tiempo de ejecuci贸n.

Con Naive Bayes, los resultados fueron constantes e invariables a trav茅s de todos los experimentos y tanto la precisi贸n como el recall se mantuvieron en 0.928922, y el tiempo de ejecuci贸n fue extremadamente bajo (entre 0.002 y 0.007 segundos). Este resultado es esperable, dado que Naive Bayes no depende de hiperpar谩metros complejos como Random Forest y es menos costoso en t茅rminos de c贸mputo.

El rendimiento general de la red neuronal (ANN) mostr贸 variabilidad, con precisiones que variaron entre 40.45% y 59.80%, donde los mejores resultados se lograron con una configuraci贸n que inclu铆a 3 capas ocultas, 32 neuronas por capa, una tasa de aprendizaje de 0.01, activaci贸n ReLU, y regularizaci贸n L2 con una tasa de 0.01. A pesar de estos ajustes, la precisi贸n promedio no super贸 los 0.60, y el tiempo de ejecuci贸n fue relativamente alto, alcanzando alrededor de 86 segundos, esto sugiere que aunque ANN puede adaptarse a configuraciones m谩s complejas, el aumento en la profundidad de la red y la regularizaci贸n no siempre se tradujo en mejoras significativas de rendimiento.

En comparaci贸n con XGBoost, tuvo un rendimiento superior y m谩s consistente, con precisiones que variaron de 59.06% a 68.98%, donde el mejor desempe帽o se obtuvo con una profundidad m谩xima de 5, una tasa de aprendizaje baja de 0.01, y 200 谩rboles estimadores, adem谩s, el tiempo de ejecuci贸n fue m谩s eficiente, promediando 44 segundos, a diferencia de ANN, el ajuste de hiperpar谩metros de XGBoost permiti贸 encontrar configuraciones que mejoraron la precisi贸n sin aumentar significativamente el tiempo de c贸mputo.

## Conclusi贸n.

Para este conjunto de pruebas, Random Forest mostr贸 el mejor equilibrio entre precisi贸n y capacidad de ajuste, logrando resultados 贸ptimos con configuraciones complejas, mientras que XGBoost destac贸 por ser el modelo m谩s eficiente entre los analizados en t茅rminos de tiempo y consistencia de rendimiento; y Naive Bayes fue la opci贸n m谩s r谩pida y sencilla, adecuada para aplicaciones donde la velocidad es importante, pero su precisi贸n, aunque ligeramente menor al resto, es aceptable. Para ANN, aunque flexible, no pudo igualar la eficiencia y precisi贸n de los dem谩s modelos, sugiriendo que puede no ser la opci贸n m谩s adecuada.

## Instrucciones de uso.

- Clona este repositorio en tu m谩quina local o descargue el repositorio en zip, asegure que el respositorio se haya descargado correctamente.
- Descomprimir el zip (en caso que se haya descargado el zip).
- Abre el programa que deseas ejecutar en tu entorno de desarrollo que soporte Python.
- Descargue las siguentes bibliotecas para poder ejecutar los programas:
  - pip install kagglehub
  - pip install pandas
  - pip install multiprocess
  - pip install scikit-learn

> [!CAUTION]
> Para evitar cualquier problema de compatibilidad, utiliza la versi贸n de Python a partir de 3.8.x hasta 3.11.x
> * kagglehub:
>   * Versi贸n m铆nima: Python 3.7.x
>   * Versi贸n m谩xima: Python 3.11.x
> * pandas:
>   * Versi贸n m铆nima: Python 3.7.x
>   * Versi贸n m谩xima: Python 3.11.x
> * multiprocess:
>   * Versi贸n m铆nima: Python 3.6.x
>   * Versi贸n m谩xima: Python 3.11.x
> * scikit-learn:
>   * Versi贸n m铆nima: Python 3.8.x
>   * Versi贸n m谩xima: Python 3.11.x

Si deseas contribuir a este repositorio, puedes enviar solicitudes de extracci贸n (pull requests) con mejoras o caracter铆sticas adicionales y si tienes alguna pregunta o problema, puedes contactarme a trav茅s de mi perfil de GitHub MrMike92, en un futuro planeo abrir un correo para poder contactarme. 
